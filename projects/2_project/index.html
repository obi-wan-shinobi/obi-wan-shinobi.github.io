<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Bachelor's Thesis Project | Shreyas Kalvankar</title> <meta name="author" content="Shreyas Kalvankar"> <meta name="description" content="Astronomical Image Colorization and up-scaling using Conditional Generative Adversarial Networks"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon.png?542484e64284bf0228dd312c245c2906"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://obi-wan-shinobi.github.io/projects/2_project/"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?e74e74bf055e5729d44a7d031a5ca6a5" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Shreyas </span>Kalvankar</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/blog/">blog</a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Bachelor's Thesis Project</h1> <p class="post-description">Astronomical Image Colorization and up-scaling using Conditional Generative Adversarial Networks</p> </header> <article> <h1 id="introduction">Introduction</h1> <p>Automated colorization of grayscale images is a burgeoning field in machine learning and computer vision with significant aesthetic and practical implications. It finds application in diverse areas, from reconstructing black and white photos to image enhancement and video restoration, improving interpretability. Super-resolution imaging aims to convert low-resolution images into high-resolution ones using a set of low-resolution images. This enhances visualization and recognition for various purposes, but it’s inherently limited by data loss during upscaling. Traditional methods rely on low-information smooth interpolation, while Generative Adversarial Networks (GANs) can hallucinate high-frequency data, though not always with desired clarity. This is particularly valuable for processing raw Hubble telescope images, which are often low-resolution and challenging to interpret due to noise and other factors. Streamlining image processing with automated colorization and super-resolution can significantly aid astronomers in analyzing vast datasets, which are continuously expanding with the introduction of new telescopes.</p> <div class="row justify-content-sm-center"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bachelor-thesis-project/samples-main-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bachelor-thesis-project/samples-main-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bachelor-thesis-project/samples-main-1400.webp"></source> <img src="/assets/img/bachelor-thesis-project/samples-main.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="colorized samples from dataset" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bachelor-thesis-project/samples-full-trained-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bachelor-thesis-project/samples-full-trained-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bachelor-thesis-project/samples-full-trained-1400.webp"></source> <img src="/assets/img/bachelor-thesis-project/samples-full-trained.jpg" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="same samples colorized using GAN" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Ground truth vs colorized images generated by our GAN </div> <h1 id="dataset-gathering">Dataset gathering</h1> <p>We initiated our project with data scraping from the Hubble Legacy Archive using a tool provided by Peh &amp; Marshland (2019). The archive contained noisy, unprocessed images, which presented substantial challenges.</p> <p>Filtering for M101 (Messier 101) galaxy images produced over 80,000 images, each differing by 1 degree in right ascension. The manual cleaning of this dataset to isolate high-resolution, well-colored images proved to be a time-consuming task.</p> <p>To overcome this, we turned to the Hubble Heritage project, renowned for its high-quality astronomical images, from which we scraped approximately 150 valuable images. Additional images were collected from the main Hubble website, totaling around 1,000.</p> <p>Due to computational limitations, we adopted 256 × 256 pixel dimensions with RGB channels. For the colorization task, we explored the utilization of the L<em>a</em>b color space, streamlining the process. We trained models in both color spaces and conducted a performance comparison.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/bachelor-thesis-project/gan-visualization-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/bachelor-thesis-project/gan-visualization-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/bachelor-thesis-project/gan-visualization-1400.webp"></source> <img src="/assets/img/bachelor-thesis-project/gan-visualization.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="GAN process diagram" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> GAN process </div> <h1 id="methodology">Methodology</h1> <p>Isola et al. (2018) introduced a general solution for various image-to-image translation tasks. Our approach is inspired by this methodology with some modifications aimed at reducing the required training data and minimizing training time while achieving similar results.</p> <p>We propose utilizing a U-net for the generator, with a pre-trained ResNet-18 network serving as the encoder. To address the challenge of “The blind leading the blind” in many image-to-image translation tasks, as identified by Ledig et al. (2017), we initially pre-train the generator independently using the Common Objects in Context (COCO) dataset and supervised learning with a mean absolute error loss function. However, this deterministic training still presents issues related to rectifying incorrect predictions.</p> <p>To overcome this, we subject the pre-trained generator to adversarial training, further enhancing its generalization. We hypothesize that this adversarial retraining will help resolve subtle color differences.</p> <p>The discriminator in our framework is based on a “Patch Discriminator” proposed by Isola et al. (2018), which produces a vector of probabilities for different localities in the input distribution, allowing us to pinpoint areas requiring correction in the generated image.</p> <p>In the final phase, we fine-tune the trained generator and discriminator to adapt to our relatively small dataset. These networks are trained adversarially using the conditional GAN objective function (Isola et al., 2018) with the introduction of noise as the L1 norm of the generated image tensor compared to the target image tensor. This approach aims to train the generator with an adversarial component while minimizing the Manhattan distance between the generator’s output and the target vector space.</p> <p>We also performed up-scaling using SR-GANs proposed by Ledig et al.(2017), you can find more information about this project in the linked publication.</p> </article> <h2>References</h2> <div class="publications"> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/kalvankar-astronomical-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/kalvankar-astronomical-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/kalvankar-astronomical-1400.webp"></source> <img src="/assets/img/publication_preview/kalvankar-astronomical.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="kalvankar-astronomical.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="kalvankar2022astronomical" class="col-sm-8"> <div class="title">Astronomical Image Colorization and Up-scaling with Conditional Generative Adversarial Networks</div> <div class="author"> <em>Shreyas Kalvankar</em>, Hrushikesh Pandit, Pranav Parwate, and <span class="more-authors" title="click to view 2 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '2 more authors' ? 'Atharva Patil, Snehal Kamalapur' : '2 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">2 more authors</span> </div> <div class="periodical"> <em></em> 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">kalvankar2022astronomical</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Astronomical Image Colorization and Up-scaling with Conditional Generative Adversarial Networks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kalvankar, Shreyas and Pandit, Hrushikesh and Parwate, Pranav and Patil, Atharva and Kamalapur, Snehal}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Gesellschaft f{\"u}r Informatik, Bonn}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2023 Shreyas Kalvankar. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Images are my own. Last updated: October 15, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>